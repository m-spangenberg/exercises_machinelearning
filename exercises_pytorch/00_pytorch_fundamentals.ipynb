{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check to see if PyTorch is available and working with our GPU. Consider using [Google Colab](https://colab.research.google.com/) if all else fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8025, 0.5420, 0.9487],\n",
      "        [0.7616, 0.2076, 0.6247],\n",
      "        [0.9549, 0.6266, 0.9909],\n",
      "        [0.4829, 0.9729, 0.2125],\n",
      "        [0.2650, 0.8753, 0.6273]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "Tensors are considered the building blocks of neural networks, and deep learning in general. Even though most references in PyTorch are to just '[tensors](https://pytorch.org/docs/stable/tensors.html)', there exists various kinds of tensors. All a tensor is in this context is \"a multi-dimensional matrix containing elements of a single data type\". We instantiate tensors using `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars\n",
    "\n",
    "$a$ - A tensor being comprised of a scalar simply means it is made of a real number and not a vector, and therefore exists in 0 dimensions. A dot, if you will.\n",
    "\n",
    "```py\n",
    "# Scalar - a real number rather than a vector\n",
    "scalar = torch.Tensor(8)\n",
    "```\n",
    "\n",
    "### Vectors\n",
    "\n",
    "$y$ - A vector is a pair of values that represent an arrow with a length and direction, with the arrows length being its magnitude and its direction being its orientation in what is called [Vector Space](https://www.youtube.com/watch?v=ozwodzD5bJM). A vector with only 1 pair of values is considered 1 dimensional, as it only represent 1 direction in Vector Space.\n",
    "\n",
    "```py\n",
    "# Vector - an object that has both a magnitude and a direction\n",
    "vector = torch.Tensor([8,8])\n",
    "```\n",
    "\n",
    "### Matrices\n",
    "\n",
    "$Q$ - A matrix is a set of numbers arranged in rows and columns to form a rectangular array and the size of this matrix is its size in element count in two dimensions.\n",
    "\n",
    "```py\n",
    "# Matrix - a 2 dimensional array of numbers\n",
    "MATRIX = torch.Tensor([[8, 8],[9, 9]])\n",
    "```\n",
    "\n",
    "### Tensors\n",
    "\n",
    "$X$ - \"A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\" -- PyTorch's Documentation. In other words: A grid of values, all of the same type, and is indexed by a tuple of nonnegative integers.\n",
    "\n",
    "```py\n",
    "# Tensor - a 3 dimensional array of numbers\n",
    "TENSOR = torch.Tensor([[[8, 8, 8],[9, 9, 9],[7, 7, 7]]])\n",
    "```\n",
    "\n",
    "### Random Tensors\n",
    "\n",
    "It is unlikely that we will ever manually assign tensor values, simply becuase of the nature of self-learning algorithms and bias. It makes much more sense to use PyTorch's built in random function to create a tensor. Remember, we start with random values and then adjust those values as the model trains.\n",
    "\n",
    "Creating random tensors in PyTorch is straightforward.\n",
    "\n",
    "```py\n",
    "randomTensor = torch.rand(1, 3, 4)\n",
    "randomTensor\n",
    "tensor([[[0.6703, 0.4746, 0.3914, 0.4547],\n",
    "         [0.7721, 0.7192, 0.2338, 0.9072],\n",
    "         [0.9905, 0.0131, 0.0025, 0.9264]]])\n",
    "```\n",
    "\n",
    "Our preprocessed input data can be represented easily by tensors. For instance, a colour image of 100 by 100 pixels would be split into Red, Green, and Blue channels and would correspond to three dimensions in our tensor represented as a: `colour_channel`, `height_channel`, and `width_channel`.\n",
    "\n",
    "```py\n",
    "# a vector consisting of 30,000 elements representing an RGB image of 100,100px\n",
    "rgb_picture = torch.rand(3,100,100)\n",
    "```\n",
    "\n",
    "### Tensor Masking\n",
    "\n",
    "If we were, for instance, required to produce a tensor that is all zeros, or all ones. We might employ what is called `maskin`. By multiplying our zero'd mask with another tensor, we can effectively mask ranges of ellements within our tensor.\n",
    "\n",
    "```py\n",
    "zmask = torch.zeros(5,5)\n",
    "randTensor = randTensor * zmask\n",
    "```\n",
    "\n",
    "### Tensors Ranges\n",
    "\n",
    "We can ask PyTorch to generate ranges with step-sizes and mask ranges with `torch.zeros_like()`\n",
    "\n",
    "```py\n",
    "one_to_ten_by_two = torch.arange(0,10,2)\n",
    "torch.zeros_like(one_to_ten_by_two)\n",
    "\n",
    "# the output should be tensor([0, 0, 0, 0, 0])\n",
    "```\n",
    "\n",
    "### Tensor Datatypes and Parameters\n",
    "\n",
    "The default datatype in PyTorch is float32, in order to change the datatype, we can assign specific datatypes as a paramater option, along with which device it should run on and wheter gradients are tracked during the operation of the tensor.\n",
    "\n",
    "```py\n",
    "a_shiny_new_tensor = torch.Tensor([3.0, 2.0, 1.0],\n",
    "                                    dtype=None,  # Datatype of the tensor\n",
    "                                    device=None,  # Device our tensor is on\n",
    "                                    requires_grad=False  # Whether or not to track gradients of this tensor\n",
    "                                    )\n",
    "```\n",
    "\n",
    "### Tensor Manipulation (Operations)\n",
    "\n",
    "Our neural network will make use of the following operations to manipulate our tensors in order to represent our dataset, this is where our inputs and channel weights are added to our baises during the feed forward portion of our neural network's learning process:\n",
    "\n",
    "1. Addition\n",
    "2. Subtraction\n",
    "3. Scalar Multiplication (multiplication by a single value)\n",
    "4. Matrix Multiplication (multiplication of matrices by matrices, [dot product](https://en.wikipedia.org/wiki/Dot_product))\n",
    "5. Division\n",
    "\n",
    "#### Addition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2])\n",
      "tensor([11, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([1,2,2])\n",
    "print(TENSOR)\n",
    "print(TENSOR + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2])\n",
      "tensor([-9, -8, -8])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([1,2,2])\n",
    "print(TENSOR)\n",
    "print(TENSOR - 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2])\n",
      "tensor([10, 20, 20])\n",
      "tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([1,2,2])\n",
    "print(TENSOR)\n",
    "print(TENSOR * 10)\n",
    "\n",
    "# also\n",
    "\n",
    "TENSOR1 = torch.tensor([1,2,3])\n",
    "TENSOR2 = torch.tensor([1,2,3])\n",
    "print(TENSOR1 * TENSOR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "TENSOR1 = torch.tensor([1,2,3])\n",
    "TENSOR2 = torch.tensor([1,2,3])\n",
    "print(torch.matmul(TENSOR1,TENSOR2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 2])\n",
      "tensor([0.1000, 0.2000, 0.2000])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([1,2,2])\n",
    "print(TENSOR)\n",
    "print(TENSOR / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "68e181086f55a8390b1f5ab0e415eb5c3167df2e6474d118b3e7b7d80e5e763c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
